<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="周雅培"><title>Microsoft makes AI debugging and visualization tool TensorWatch open source · 人生印记</title><meta name="description" content="The rise of deep learning is accompanied by ever-increasing model complexity, larger datasets, and longer training times for models. When working on n"><meta name="keywords" content><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">Write Code, Blow Minds.</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">雅培の人生印记</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li class="soc"><a href="https://github.com/FriggaAZ" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a><a href="https://www.instagram.com/__limbo" target="_blank" rel="noopener noreferrer"><i class="fa fa-instagram">&nbsp;</i></a><a href="http://www.yapei97.com/atom.xml" target="_blank" rel="noopener noreferrer"><i class="fa fa-rss">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2019&nbsp;<a target="_blank" href="http://www.yapei97.com" rel="noopener noreferrer">周雅培</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;</p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>Microsoft makes AI debugging and visualization tool TensorWatch open source</a></p><p class="post-meta"><span class="date meta-item">发布于&nbsp;2019-07-09</span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/AI/" title="AI" class="a-tag">AI</a><span>&nbsp;</span></span></p><p class="post-abstract"></p><p><a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/06/TensorWatch-A-debugging-and-visualization-system-for-machine-learning_Site_06_2019_1400x788.png" target="_blank" rel="noopener"><img src="https://www.microsoft.com/en-us/research/uploads/prod/2019/06/TensorWatch-A-debugging-and-visualization-system-for-machine-learning_Site_06_2019_1400x788-1024x576.png" alt="TensorWatch"></a></p>
<p>The rise of deep learning is accompanied by ever-increasing model complexity, larger datasets, and longer training times for models. When working on novel concepts, researchers often need to understand why training metrics are trending the way they are. So far, the available tools for machine learning training have focused on a “what you see is what you log” approach. As logging is relatively expensive, researchers and engineers tend to avoid it and rely on a few signals to guesstimate the cause of the patterns they see. At Microsoft Research, we’ve been asking important questions surrounding this very challenge: What if we could dramatically reduce the cost of getting more information about the state of the system? What if we had advanced tooling that could help researchers make more informed decisions effectively?</p>
<h3 id="Introducing-TensorWatch"><a href="#Introducing-TensorWatch" class="headerlink" title="Introducing TensorWatch"></a>Introducing TensorWatch</h3><p>We’re happy to introduce <a href="https://github.com/microsoft/tensorwatch" target="_blank" rel="noopener">TensorWatch</a>, an open-source system that implements several of these ideas and concepts. We like to think of TensorWatch as the Swiss Army knife of debugging tools with many advanced capabilities researchers and engineers will find helpful in their work. We presented TensorWatch at the <a href="https://eics.acm.org/2019/" target="_blank" rel="noopener">2019 ACM SIGCHI Symposium on Engineering Interactive Computing Systems</a>.</p>
<h3 id="Custom-UIs-and-visualizations"><a href="#Custom-UIs-and-visualizations" class="headerlink" title="Custom UIs and visualizations"></a>Custom UIs and visualizations</h3><p>The first thing you might notice when using TensorWatch is it extensively leverages Jupyter Notebook instead of prepackaged user interfaces, which are often difficult to customize. TensorWatch provides the interactive debugging of real-time training processes using either the composable UI in Jupyter Notebooks or the live shareable dashboards in Jupyter Lab. In addition, since TensorWatch is a Python library, you can also build your own custom UIs or use TensorWatch in the vast Python data science ecosystem. TensorWatch also supports several standard visualization types, including bar charts, histograms, and pie charts, as well as 3D variations.</p>
<p><img src="https://www.microsoft.com/en-us/research/uploads/prod/2019/06/TensorWatch-Image-1.gif" alt="With TensorWatch—a debugging and visualization tool for machine learning—researchers and engineers can customize the user interface to accommodate a variety of scenarios. Above is an example of TensorWatch running in Jupyter Notebook, rendering a live chart from multiple streams produced by an ML training application."></p>
<p>With TensorWatch—a debugging and visualization tool for machine learning—researchers and engineers can customize the user interface to accommodate a variety of scenarios. Above is an example of TensorWatch running in Jupyter Notebook, rendering a live chart from multiple streams produced by an ML training application.</p>
<h3 id="Streams-streams-everywhere"><a href="#Streams-streams-everywhere" class="headerlink" title="Streams, streams everywhere"></a>Streams, streams everywhere</h3><p>One of the central premises of the TensorWatch architecture is we uniformly treat data and other objects as streams. This includes files, console, sockets, cloud storage, and even visualizations themselves. With a common interface, TensorWatch streams can listen to other streams, which enables the creation of custom data flow graphs. Using these concepts, TensorWatch trivially allows you to implement a variety of advanced scenarios. For example, you can render many streams into the same visualization, or one stream can be rendered in many visualizations simultaneously, or a stream can be persisted in many files, or not persisted at all. The possibilities are endless!</p>
<p><img src="https://www.microsoft.com/en-us/research/uploads/prod/2019/06/TensorWatch-Image-2.gif" alt="TensorWatch supports a variety of visualization types. Above is an example of a TensorWatch t-SNE visualization of the MNIST dataset."></p>
<p>TensorWatch supports a variety of visualization types. Above is an example of a TensorWatch t-SNE visualization of the MNIST dataset.</p>
<h3 id="Lazy-logging-mode"><a href="#Lazy-logging-mode" class="headerlink" title="Lazy logging mode"></a>Lazy logging mode</h3><p>With TensorWatch, we also introduce <em>lazy logging mode</em>. This mode doesn’t require explicit logging of all the information beforehand. Instead, you can have TensorWatch observe the variables. Since observing is basically free, you can track as many variables as you like, including large models or entire batches during the training. TensorWatch then allows you to perform interactive queries that run in the context of these variables and returns the streams as a result. These streams can then be visualized, saved, or processed as needed. For example, you can write a lambda expression that computes mean weight gradients in each layer in the model at the completion of each batch and send the result as a stream of tensors that can be plotted as a bar chart.</p>
<h3 id="Phases-of-model-development"><a href="#Phases-of-model-development" class="headerlink" title="Phases of model development"></a>Phases of model development</h3><p>At Microsoft Research, we care deeply about improving debugging capabilities in all phases of model development—pre-training, in-training, and post-training. Consequently, TensorWatch provides many features useful for pre- and post-training phases as well. We lean on several excellent open-source libraries to enable many of <a href="https://github.com/microsoft/tensorwatch#pre-training-and-post-training-tasks" target="_blank" rel="noopener">these features</a>, which include model graph visualization, data exploration through dimensionality reduction, model statistics, and several prediction explainers for convolution networks.</p>
<h3 id="Open-source-on-GitHub"><a href="#Open-source-on-GitHub" class="headerlink" title="Open source on GitHub"></a>Open source on GitHub</h3><p>We hope TensorWatch helps spark further advances and ideas for efficiently debugging and visualizing machine learning and invite the ML community to participate in this journey via <a href="https://github.com/microsoft/tensorwatch" target="_blank" rel="noopener">GitHub</a>.</p>
<blockquote>
<p><a href="https://www.microsoft.com/en-us/research/blog/microsoft-makes-ai-debugging-and-visualization-tool-tensorwatch-open-source/" target="_blank" rel="noopener">Microsoft makes AI debugging and visualization tool TensorWatch open source</a></p>
<p>Author：June 25, 2019 | By <a href="https://www.microsoft.com/en-us/research/people/shitals/" target="_blank" rel="noopener">Shital Shah</a>, Principal Research Engineer; <a href="https://www.microsoft.com/en-us/research/people/rfernand/" target="_blank" rel="noopener">Roland Fernandez</a>, Senior Researcher; <a href="https://www.microsoft.com/en-us/research/people/sdrucker/" target="_blank" rel="noopener">Steven Drucker</a>, Principal Researcher; <a href="http://www.linkedin.com/in/maxiluk" target="_blank" rel="noopener">Maxim Lukiyanov</a>, Principal Program Manager; <a href="https://www.microsoft.com/en-us/research/people/sdumais/" target="_blank" rel="noopener">Susan Dumais</a>, Technical Fellow, Deputy Managing Director</p>
</blockquote>
<p></p></div><div class="share"><span>分享到</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a href="http://twitter.com/home?status=http://www.yapei97.com/2019/07/09/Microsoft-makes-AI-debugging-and-visualization-tool-TensorWatch-open-source/%20人生印记%20Microsoft makes AI debugging and visualization tool TensorWatch open source" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/2019/07/10/TensorWatch/" title="微软开源AI故障诊断和可视化工具"><i class="fa fa-angle-double-left"></i>&nbsp;上一篇: 微软开源AI故障诊断和可视化工具</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2019/06/19/Object-Oriented-Programming/" title="Object-Oriented-Programming">下一篇: Object-Oriented-Programming&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div><div id="lv-container" data-id="city" data-uid="MTAyMC80NTE2Ni8yMTY4Mw=="><script type="text/javascript">(function (d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') {
        return;
    }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
})(document, 'script');</script><noscript> Please activate JavaScript for write a comment in LiveRe</noscript></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2019&nbsp;<a target="_blank" href="http://www.yapei97.com" rel="noopener noreferrer">周雅培</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;</p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>